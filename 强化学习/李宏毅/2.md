# Policy Gradient

具体的实施步骤

<img src="images/image-20211202135620963.png" alt="image-20211202135620963" style="zoom:50%;" />

为什么会有log呢？将actor看成是一个分类器：

<img src="images/image-20211202163413269.png" alt="image-20211202163413269" style="zoom:50%;" />

因此，当把R(τ)省略不看的时候，每个τ相当于给actor这个分类器提供了training data：

<img src="images/image-20211202164951942.png" alt="image-20211202164951942" style="zoom: 50%;" />

然后与正常的regression不同的是：**这里有了R(τ)，**就相当于在**训练一个分类器的时候加了权重**，每次训练完一次后，又得到新的training data，如此往复。

<img src="images/image-20211202165342270.png" alt="image-20211202165342270" style="zoom:50%;" />